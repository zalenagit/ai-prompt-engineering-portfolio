# AI Prompt Engineering Portfolio  
Created by Zalina Yusop  

This portfolio showcases my work in **prompt engineering**, **AI evaluation**, **LLM safety testing**, and **QA-style analysis for AI systems**.  
It is designed to demonstrate the skills required for remote roles such as:

- Prompt Engineer  
- AI Evaluator / Rater  
- AI Safety Analyst  
- AI QA Specialist  
- LLM Content & Quality Reviewer  

Each project highlights a different competency used in real-world AI workflows.

---

## üìÅ Project Overview

### **1. Prompt Library & Structured Prompt Design**
A curated library of 30+ prompts covering:
- Classification  
- Summarization  
- Rewriting  
- Tone transformation  
- JSON extraction  
- Chain-of-thought reasoning  
- Safety & bias detection  

üìÇ Folder: `project-01-prompt-library`

---

### **2. AI Output Evaluation & Quality Scoring**
A structured evaluation of AI model responses using criteria such as:
- Accuracy  
- Completeness  
- Safety  
- Bias  
- Hallucinations  

üìÇ Folder: `project-02-ai-output-evaluation`

---

### **3. Chain-of-Thought Prompting & Multi-Step Reasoning**
Demonstrates advanced prompting techniques:
- Step-by-step reasoning  
- Structured output formats  
- Iterative refinement  
- Error analysis  

üìÇ Folder: `project-03-chain-of-thought`

---

### **4. AI Test Plan (QA + AI Hybrid Project)**
Applies QA engineering methodology to AI systems:
- Functional test cases  
- Edge cases  
- Negative tests  
- Safety tests  
- Output consistency checks  

üìÇ Folder: `project-04-ai-test-plan`

---

### **5. AI Safety Audit & Risk Assessment**
Evaluates AI responses to:
- Harmful prompts  
- Biased phrasing  
- Sensitive topics  
- Misinformation traps  

üìÇ Folder: `project-05-ai-safety-audit`

---

## üß† Skills Demonstrated

### **Prompt Engineering**
- Prompt design & optimization  
- Chain-of-thought prompting  
- Multi-step reasoning  
- Output formatting & constraints  

### **AI Evaluation**
- Quality scoring  
- Safety analysis  
- Bias detection  
- Hallucination identification  

### **QA Engineering**
- Test planning  
- Edge-case analysis  
- Regression-style evaluation  
- Documentation & reporting  

### **Technical**
- Markdown documentation  
- Git & GitHub workflow  
- VS Code + WSL development  
- JSON, structured outputs  

---

## üéØ Purpose of This Portfolio
This repository was created to demonstrate practical, hands-on skills for remote AI roles.  
It reflects real tasks performed by:

- Prompt Engineers  
- AI Evaluators  
- AI Safety Reviewers  
- LLM Testers  
- Data Annotation Specialists  

It also bridges my background in **QA engineering** with modern **AI evaluation workflows**.

---

## üì¨ Contact
**Zalina Yusop**  
Dallas, TX  
GitHub: https://github.com/zalenagit  
Email: noryuszalinamyusop@gmail.com

---

## ‚≠ê Final Notes
This portfolio will continue to grow with additional projects, including:
- Retrieval-augmented generation (RAG) prompts  
- Multi-agent prompting  
- Advanced safety evaluations  
- Automation scripts for AI testing  

Stay tuned for updates!
